import torch
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import os
from ddpm_model import DDPMModel
import time

# æ£€æŸ¥æ˜¯å¦æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ
try:
    from torch.cuda.amp import autocast, GradScaler
    AMP_AVAILABLE = True
except ImportError:
    AMP_AVAILABLE = False

def get_native_high_res_dataloader(
    dataset_name='stl10', 
    batch_size=16, 
    num_workers=None,
    use_upsampling=False,
    target_size=None
):
    """è·å–åŸç”Ÿé«˜åˆ†è¾¨ç‡æ•°æ®åŠ è½½å™¨"""
    
    if num_workers is None:
        num_workers = min(8, os.cpu_count() or 4)
    
    # æ ¹æ®æ•°æ®é›†ç¡®å®šåŸç”Ÿåˆ†è¾¨ç‡
    if dataset_name.lower() == 'cifar10':
        native_size = 32
        if not use_upsampling:
            print("âš ï¸ CIFAR-10åŸç”Ÿåˆ†è¾¨ç‡ä¸º32x32")
            print("   å»ºè®®ä½¿ç”¨STL-10(96x96)æˆ–CelebA(64x64)è·å¾—çœŸæ­£çš„é«˜åˆ†è¾¨ç‡")
            print("   æˆ–è€…è®¾ç½®use_upsampling=Trueè¿›è¡Œä¸Šé‡‡æ ·")
    elif dataset_name.lower() == 'stl10':
        native_size = 96
    elif dataset_name.lower() == 'celeba':
        native_size = 64  # CelebAåŸå§‹æ˜¯æ›´é«˜çš„ï¼Œä½†é€šå¸¸cropåˆ°64x64
    else:
        native_size = 64  # é»˜è®¤
    
    # å†³å®šæœ€ç»ˆçš„å›¾åƒå°ºå¯¸
    if target_size is None:
        image_size = native_size
    else:
        image_size = target_size
        if target_size > native_size and not use_upsampling:
            print(f"âš ï¸ è­¦å‘Šï¼šç›®æ ‡å°ºå¯¸{target_size}å¤§äºåŸç”Ÿå°ºå¯¸{native_size}")
            print("   è¿™ä¼šå¯¼è‡´ä¸Šé‡‡æ ·ï¼Œå»ºè®®ä½¿ç”¨åŸç”Ÿå°ºå¯¸æˆ–æ›´é«˜åˆ†è¾¨ç‡æ•°æ®é›†")
    
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"   - æ•°æ®é›†: {dataset_name.upper()}")
    print(f"   - åŸç”Ÿåˆ†è¾¨ç‡: {native_size}x{native_size}")
    print(f"   - è®­ç»ƒåˆ†è¾¨ç‡: {image_size}x{image_size}")
    print(f"   - æ˜¯å¦ä¸Šé‡‡æ ·: {'æ˜¯' if image_size > native_size else 'å¦'}")
    
    # æ„å»ºå˜æ¢ç®¡é“
    transforms_list = []
    
    # åŸºç¡€å°ºå¯¸è°ƒæ•´
    if image_size != native_size:
        if image_size < native_size:
            # ä¸‹é‡‡æ ·ï¼šå…ˆresizeå†crop
            transforms_list.extend([
                transforms.Resize(image_size),
                transforms.CenterCrop(image_size)
            ])
        else:
            # ä¸Šé‡‡æ ·ï¼šå‘å‡ºè­¦å‘Š
            if use_upsampling:
                transforms_list.extend([
                    transforms.Resize(image_size),
                    transforms.CenterCrop(image_size)
                ])
                print("ğŸ”„ æ­£åœ¨è¿›è¡Œä¸Šé‡‡æ ·ï¼Œå›¾åƒè´¨é‡å¯èƒ½å—å½±å“")
            else:
                raise ValueError(f"ç›®æ ‡å°ºå¯¸{image_size}å¤§äºåŸç”Ÿå°ºå¯¸{native_size}ï¼Œè¯·è®¾ç½®use_upsampling=True")
    
    # æ•°æ®å¢å¼º
    augment_transforms = []  # type: ignore
    augment_transforms.append(transforms.RandomHorizontalFlip(p=0.5))
    
    # å¯¹äºé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¯ä»¥æ·»åŠ æ›´å¤šå¢å¼º
    if image_size >= 64:
        augment_transforms.append(transforms.RandomRotation(5))  # è½»å¾®æ—‹è½¬
        # augment_transforms.append(transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05))
    
    # æœ€ç»ˆå˜æ¢
    final_transforms = [
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ]
    
    # ç»„åˆæ‰€æœ‰å˜æ¢
    transform = transforms.Compose(transforms_list + augment_transforms + final_transforms)
    
    # åˆ›å»ºæ•°æ®é›†
    if dataset_name.lower() == 'cifar10':
        dataset = torchvision.datasets.CIFAR10(
            root='./data',
            train=True,
            download=True,
            transform=transform
        )
    elif dataset_name.lower() == 'stl10':
        dataset = torchvision.datasets.STL10(
            root='./data',
            split='train',
            download=True,
            transform=transform
        )
        print("âœ… ä½¿ç”¨STL-10æ•°æ®é›†ï¼ŒåŸç”Ÿ96x96åˆ†è¾¨ç‡")
    elif dataset_name.lower() == 'celeba':
        try:
            # CelebAçš„ç‰¹æ®Šå¤„ç†
            celeba_transform = transforms.Compose([
                transforms.CenterCrop(178),  # CelebAæ¨èçš„crop
                transforms.Resize(image_size),
                *augment_transforms,
                *final_transforms
            ])
            
            dataset = torchvision.datasets.CelebA(
                root='./data',
                split='train',
                download=False,  # éœ€è¦æ‰‹åŠ¨ä¸‹è½½
                transform=celeba_transform
            )
            print("âœ… ä½¿ç”¨CelebAæ•°æ®é›†ï¼Œé«˜è´¨é‡äººè„¸å›¾åƒ")
        except Exception as e:
            print(f"âŒ CelebAåŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ CelebAéœ€è¦æ‰‹åŠ¨ä¸‹è½½ï¼Œè¯·å‚è€ƒï¼š")
            print("   https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html")
            raise
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset_name}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2,
        drop_last=True
    )
    
    return dataloader, dataset, image_size

def train_true_high_res_ddpm(
    dataset_name='stl10',
    target_size=None,  # Noneè¡¨ç¤ºä½¿ç”¨åŸç”Ÿåˆ†è¾¨ç‡
    use_upsampling=False,
    epochs=50,
    batch_size=None,
    learning_rate=1e-4,
    save_interval=10,
    use_amp=True,
    compile_model=True
):
    """è®­ç»ƒçœŸæ­£çš„é«˜åˆ†è¾¨ç‡DDPMæ¨¡å‹"""
    
    print("ğŸ¯ çœŸæ­£çš„é«˜åˆ†è¾¨ç‡DDPMè®­ç»ƒ")
    print("=" * 50)
    
    # è·å–æ•°æ®åŠ è½½å™¨
    dataloader, dataset, image_size = get_native_high_res_dataloader(
        dataset_name=dataset_name,
        target_size=target_size,
        use_upsampling=use_upsampling,
        batch_size=batch_size or 16
    )
    
    # è·å–GPUä¿¡æ¯å¹¶è°ƒæ•´æ‰¹æ¬¡å¤§å°
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        if '3060' in gpu_name:
            gpu_memory = 12
        elif '3090' in gpu_name or '4090' in gpu_name:
            gpu_memory = 24
        elif '3080' in gpu_name:
            gpu_memory = 10
        else:
            gpu_memory = 8
        print(f"ğŸ–¥ï¸  GPU: {gpu_name} ({gpu_memory}GB)")
    else:
        gpu_memory = 0
        print("ğŸ–¥ï¸  è®¾å¤‡: CPU")
    
    # æ™ºèƒ½æ‰¹æ¬¡å¤§å°è°ƒæ•´
    if batch_size is None:
        if image_size <= 32:
            batch_size = 32 if gpu_memory >= 12 else 16
        elif image_size <= 64:
            batch_size = 16 if gpu_memory >= 12 else 8
        elif image_size <= 96:
            batch_size = 12 if gpu_memory >= 12 else 6
        else:
            batch_size = 8 if gpu_memory >= 12 else 4
    
    # é‡æ–°åˆ›å»ºdataloader withæ­£ç¡®çš„batch_size
    dataloader, dataset, image_size = get_native_high_res_dataloader(
        dataset_name=dataset_name,
        target_size=target_size,
        use_upsampling=use_upsampling,
        batch_size=batch_size
    )
    
    # æ ¹æ®åˆ†è¾¨ç‡é…ç½®æ¨¡å‹
    if image_size <= 32:
        model_config = {'dim': 64, 'dim_mults': (1, 2, 4, 8)}
    elif image_size <= 64:
        model_config = {'dim': 128, 'dim_mults': (1, 2, 4, 8)}
    elif image_size <= 96:
        model_config = {'dim': 160, 'dim_mults': (1, 2, 4, 8)}
    else:
        model_config = {'dim': 192, 'dim_mults': (1, 1, 2, 2, 4, 4)}
    
    print(f"ğŸ—ï¸  æ¨¡å‹é…ç½®:")
    print(f"   - æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   - æ¨¡å‹ç»´åº¦: {model_config['dim']}")
    print(f"   - å±‚çº§å€æ•°: {model_config['dim_mults']}")
    
    # åˆ›å»ºæ¨¡å‹
    model = DDPMModel(
        image_size=image_size,
        channels=3,
        timesteps=1000,
        **model_config
    )
    
    total_params = sum(p.numel() for p in model.unet.parameters())
    print(f"   - æ¨¡å‹å‚æ•°: {total_params:,}")
    
    # æ¨¡å‹ç¼–è¯‘
    if compile_model and hasattr(torch, 'compile'):
        try:
            compiled_unet = torch.compile(model.unet)
            model.unet = compiled_unet  # type: ignore
            print("âœ… æ¨¡å‹ç¼–è¯‘æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹ç¼–è¯‘å¤±è´¥: {e}")
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.unet.parameters(),
        lr=learning_rate,
        weight_decay=0.01,
        betas=(0.9, 0.999)
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=epochs, eta_min=learning_rate * 0.1
    )
    
    # æ··åˆç²¾åº¦
    scaler = GradScaler() if use_amp and AMP_AVAILABLE else None
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    exp_name = f"{dataset_name}_native_{image_size}x{image_size}"
    if use_upsampling and target_size:
        exp_name = f"{dataset_name}_upsampled_{image_size}x{image_size}"
    
    os.makedirs(f'checkpoints/{exp_name}', exist_ok=True)
    os.makedirs(f'samples/{exp_name}', exist_ok=True)
    os.makedirs(f'training_progress/{exp_name}', exist_ok=True)
    
    print(f"ğŸ“ å®éªŒåç§°: {exp_name}")
    print("=" * 60)
    
    # è®­ç»ƒå¾ªç¯
    losses = []
    best_loss = float('inf')
    training_start_time = time.time()
    
    for epoch in range(epochs):
        model.unet.train()
        epoch_losses = []
        epoch_start_time = time.time()
        
        pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}')
        for batch_idx, (data, _) in enumerate(pbar):
            optimizer.zero_grad()
            
            if use_amp and scaler is not None:
                with autocast():
                    loss = model.train_step(data)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                loss = model.train_step(data)
                loss.backward()
                optimizer.step()
            
            epoch_losses.append(loss.item())
            
            current_lr = scheduler.get_last_lr()[0]
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'lr': f'{current_lr:.2e}'
            })
        
        scheduler.step()
        
        # Epochç»Ÿè®¡
        epoch_time = time.time() - epoch_start_time
        avg_loss = np.mean(epoch_losses)
        losses.append(avg_loss)
        
        print(f'ğŸ“Š Epoch {epoch+1}/{epochs}:')
        print(f'   â±ï¸  ç”¨æ—¶: {epoch_time:.2f}ç§’')
        print(f'   ğŸ“‰ å¹³å‡æŸå¤±: {avg_loss:.4f}')
        print(f'   ğŸ“ˆ å­¦ä¹ ç‡: {current_lr:.2e}')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_loss < best_loss:
            best_loss = avg_loss
            best_path = f'checkpoints/{exp_name}/ddpm_best.pt'
            model.save_model(best_path)
            print(f'   ğŸ† æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜')
        
        # å¿«é€Ÿé‡‡æ ·
        if (epoch + 1) % 5 == 0:
            model.unet.eval()
            with torch.no_grad():
                sample_count = min(9, batch_size)
                quick_samples = model.sample(batch_size=sample_count)
                save_native_samples(
                    quick_samples,
                    f'training_progress/{exp_name}/quick_epoch_{epoch+1}.png',
                    epoch=epoch+1,
                    loss=avg_loss,
                    image_size=image_size,
                    is_native=not use_upsampling
                )
            print(f'   ğŸ“¸ å¿«é€Ÿé‡‡æ ·å·²ä¿å­˜')
        
        # æ£€æŸ¥ç‚¹ä¿å­˜
        if (epoch + 1) % save_interval == 0:
            checkpoint_path = f'checkpoints/{exp_name}/ddpm_epoch_{epoch+1}.pt'
            model.save_model(checkpoint_path)
            
            model.unet.eval()
            with torch.no_grad():
                samples = model.sample(batch_size=16)
                save_native_samples(
                    samples,
                    f'samples/{exp_name}/epoch_{epoch+1}_samples.png',
                    epoch=epoch+1,
                    loss=avg_loss,
                    image_size=image_size,
                    is_native=not use_upsampling
                )
            
            plot_native_losses(losses, f'samples/{exp_name}/loss_curve_epoch_{epoch+1}.png', exp_name)
            print(f'   ğŸ’¾ å®Œæ•´æ£€æŸ¥ç‚¹å·²ä¿å­˜')
        
        print("-" * 50)
    
    # è®­ç»ƒå®Œæˆ
    total_time = time.time() - training_start_time
    final_path = f'checkpoints/{exp_name}/ddpm_final.pt'
    model.save_model(final_path)
    
    print("ğŸ‰ çœŸæ­£çš„é«˜åˆ†è¾¨ç‡è®­ç»ƒå®Œæˆï¼")
    print(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {total_time/3600:.2f}å°æ—¶")
    print(f"ğŸ“‰ æœ€ä½³æŸå¤±: {best_loss:.4f}")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {final_path}")
    
    return model, losses

def save_native_samples(samples, path, epoch=None, loss=None, image_size=64, is_native=True):
    """ä¿å­˜åŸç”Ÿé«˜åˆ†è¾¨ç‡æ ·æœ¬"""
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        samples = (samples + 1) / 2
        samples = torch.clamp(samples, 0, 1)
        
        nrow = 3 if len(samples) <= 9 else 4
        grid = torchvision.utils.make_grid(samples, nrow=nrow, padding=2)
        grid_np = grid.permute(1, 2, 0).cpu().numpy()
        
        fig_size = max(8, image_size // 12)
        plt.figure(figsize=(fig_size, fig_size))
        plt.imshow(grid_np)
        plt.axis('off')
        
        title = f'Epoch {epoch} - Loss: {loss:.4f} ({image_size}x{image_size})'
        if is_native:
            title += ' [åŸç”Ÿåˆ†è¾¨ç‡]'
        else:
            title += ' [ä¸Šé‡‡æ ·]'
        
        if epoch is not None and loss is not None:
            plt.title(title, fontsize=14, fontweight='bold')
        
        dpi = 200 if image_size >= 64 else 150
        plt.savefig(path, bbox_inches='tight', dpi=dpi)
        plt.close()
        
    except Exception as e:
        print(f"ä¿å­˜æ ·æœ¬æ—¶å‡ºé”™: {e}")

def plot_native_losses(losses, path, exp_name):
    """ç»˜åˆ¶åŸç”Ÿé«˜åˆ†è¾¨ç‡è®­ç»ƒæŸå¤±"""
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        plt.figure(figsize=(12, 6))
        plt.plot(losses, linewidth=2, color='blue')
        plt.title(f'Training Loss - {exp_name}', fontsize=16, fontweight='bold')
        plt.xlabel('Epoch', fontsize=12)
        plt.ylabel('Loss', fontsize=12)
        plt.grid(True, alpha=0.3)
        
        if losses:
            min_loss_idx = np.argmin(losses)
            min_loss = losses[min_loss_idx]
            plt.scatter([min_loss_idx], [min_loss], color='red', s=100, zorder=5)
            plt.annotate(f'Best: {min_loss:.4f}', 
                        xy=(float(min_loss_idx), float(min_loss)),
                        xytext=(10, 10), textcoords='offset points',
                        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7))
        
        plt.tight_layout()
        plt.savefig(path, bbox_inches='tight', dpi=150)
        plt.close()
        
    except Exception as e:
        print(f"ä¿å­˜æŸå¤±æ›²çº¿æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    import sys
    
    print("ğŸ¯ çœŸæ­£çš„é«˜åˆ†è¾¨ç‡DDPMè®­ç»ƒ")
    print("æ¨èçš„æ•°æ®é›†ç»„åˆ:")
    print("  1. STL-10 (åŸç”Ÿ96x96) - python train_true_high_res.py stl10")
    print("  2. CelebA (åŸç”Ÿ64x64) - python train_true_high_res.py celeba")
    print("  3. CIFAR-10 (åŸç”Ÿ32x32) - python train_true_high_res.py cifar10")
    print()
    
    # è§£æå‚æ•°
    dataset_name = sys.argv[1] if len(sys.argv) > 1 else 'stl10'
    target_size = int(sys.argv[2]) if len(sys.argv) > 2 else None
    use_upsampling = '--allow-upsampling' in sys.argv
    
    print(f"é€‰æ‹©çš„æ•°æ®é›†: {dataset_name}")
    if target_size:
        print(f"ç›®æ ‡åˆ†è¾¨ç‡: {target_size}x{target_size}")
    print(f"å…è®¸ä¸Šé‡‡æ ·: {'æ˜¯' if use_upsampling else 'å¦'}")
    print("=" * 60)
    
    try:
        model, losses = train_true_high_res_ddpm(
            dataset_name=dataset_name,
            target_size=target_size,
            use_upsampling=use_upsampling,
            epochs=50,
            use_amp='--no-amp' not in sys.argv,
            compile_model='--no-compile' not in sys.argv
        )
        
        print("ğŸ‰ çœŸæ­£çš„é«˜åˆ†è¾¨ç‡è®­ç»ƒæˆåŠŸå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc() 