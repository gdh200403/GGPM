import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import os
from ddpm_model import DDPMModel
import time
from PIL import Image

def load_true_high_res_model(model_path, device='auto'):
    """åŠ è½½çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ¨¡å‹ï¼ˆé€‚é…train_true_high_res.pyè®­ç»ƒçš„æ¨¡å‹ï¼‰"""
    if device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    print(f"ğŸ“‚ åŠ è½½çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ¨¡å‹: {model_path}")
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {device}")
    
    # ä»è·¯å¾„æ¨æ–­é…ç½®ï¼ˆé€‚é…train_true_high_res.pyçš„å‘½åè§„åˆ™ï¼‰
    filename = os.path.basename(model_path)
    directory = os.path.dirname(model_path)
    
    # è§£æå®éªŒåç§°
    config_detected = False
    
    # æ£€æŸ¥ç›®å½•ç»“æ„ï¼šcheckpoints/{dataset}_native_{size}x{size}/
    if 'checkpoints' in directory:
        parts = directory.split('/')
        for part in parts:
            if 'native' in part or 'upsampled' in part:
                exp_name = part
                print(f"ğŸ” æ£€æµ‹åˆ°å®éªŒåç§°: {exp_name}")
                
                # è§£ææ•°æ®é›†å’Œå°ºå¯¸
                if 'cifar10_native_32x32' in exp_name:
                    image_size = 32
                    dataset = 'cifar10'
                    config = {'dim': 64, 'dim_mults': (1, 2, 4, 8)}
                    config_detected = True
                elif 'stl10_native_96x96' in exp_name:
                    image_size = 96
                    dataset = 'stl10'
                    config = {'dim': 160, 'dim_mults': (1, 2, 4, 8)}
                    config_detected = True
                elif 'celeba_native_64x64' in exp_name:
                    image_size = 64
                    dataset = 'celeba'
                    config = {'dim': 128, 'dim_mults': (1, 2, 4, 8)}
                    config_detected = True
                elif 'native_64x64' in exp_name:
                    image_size = 64
                    dataset = 'unknown'
                    config = {'dim': 128, 'dim_mults': (1, 2, 4, 8)}
                    config_detected = True
                elif 'native_96x96' in exp_name:
                    image_size = 96
                    dataset = 'unknown'
                    config = {'dim': 160, 'dim_mults': (1, 2, 4, 8)}
                    config_detected = True
                elif 'upsampled' in exp_name:
                    # è§£æä¸Šé‡‡æ ·æ¨¡å‹
                    size_parts = [p for p in exp_name.split('_') if 'x' in p and p.replace('x', '').replace('x', '').isdigit()]
                    if size_parts:
                        size_str = size_parts[0]
                        image_size = int(size_str.split('x')[0])
                        dataset = exp_name.split('_')[0]
                        
                        if image_size <= 32:
                            config = {'dim': 64, 'dim_mults': (1, 2, 4, 8)}
                        elif image_size <= 64:
                            config = {'dim': 128, 'dim_mults': (1, 2, 4, 8)}
                        elif image_size <= 96:
                            config = {'dim': 160, 'dim_mults': (1, 2, 4, 8)}
                        else:
                            config = {'dim': 192, 'dim_mults': (1, 1, 2, 2, 4, 4)}
                        config_detected = True
                break
    
    # å¦‚æœæ— æ³•ä»è·¯å¾„æ¨æ–­ï¼Œå°è¯•ä»æ–‡ä»¶åæ¨æ–­
    if not config_detected:
        print("âš ï¸ æ— æ³•ä»è·¯å¾„æ¨æ–­é…ç½®ï¼Œå°è¯•ä»æ–‡ä»¶åæ¨æ–­...")
        
        if 'stl10' in filename.lower():
            image_size = 96
            dataset = 'stl10'
            config = {'dim': 160, 'dim_mults': (1, 2, 4, 8)}
        elif 'celeba' in filename.lower():
            image_size = 64  
            dataset = 'celeba'
            config = {'dim': 128, 'dim_mults': (1, 2, 4, 8)}
        elif 'cifar10' in filename.lower():
            image_size = 32
            dataset = 'cifar10'
            config = {'dim': 64, 'dim_mults': (1, 2, 4, 8)}
        else:
            # é»˜è®¤é…ç½®
            image_size = 64
            dataset = 'unknown'
            config = {'dim': 128, 'dim_mults': (1, 2, 4, 8)}
            print("âš ï¸ æ— æ³•æ¨æ–­é…ç½®ï¼Œä½¿ç”¨é»˜è®¤64x64é…ç½®")
    
    model = DDPMModel(
        image_size=image_size,
        channels=3,
        timesteps=1000,
        device=device,
        **config
    )
    
    model.load_model(model_path)
    model.unet.eval()
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.unet.parameters())
    print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   - æ•°æ®é›†: {dataset.upper()}")
    print(f"   - å›¾åƒå°ºå¯¸: {image_size}x{image_size}")
    print(f"   - å‚æ•°æ•°é‡: {total_params:,}")
    print(f"   - æ¨¡å‹ç»´åº¦: {config['dim']}")
    print(f"   - å±‚çº§å€æ•°: {config['dim_mults']}")
    
    return model, image_size, dataset

def generate_true_high_res_samples(
    model, 
    num_samples=16, 
    save_path=None, 
    sampling_steps=None,
    show_progress=True,
    dataset_name='unknown'
):
    """ç”ŸæˆçœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ ·æœ¬"""
    
    print(f"ğŸ¨ å¼€å§‹ç”Ÿæˆ {num_samples} ä¸ªçœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ ·æœ¬")
    
    device = model.device
    
    # æ ¹æ®æ¨¡å‹å’Œæ•°æ®é›†è‡ªåŠ¨è°ƒæ•´é‡‡æ ·æ­¥æ•°
    if sampling_steps is None:
        if dataset_name == 'cifar10':
            sampling_steps = 250  # CIFAR-10å¯ä»¥ç”¨è¾ƒå°‘æ­¥æ•°
        elif dataset_name == 'stl10':
            sampling_steps = 500  # STL-10éœ€è¦æ›´å¤šæ­¥æ•°
        elif dataset_name == 'celeba':
            sampling_steps = 400  # CelebAä¸­ç­‰æ­¥æ•°
        else:
            # æ ¹æ®åˆ†è¾¨ç‡å†³å®š
            if model.image_size <= 32:
                sampling_steps = 250
            elif model.image_size <= 64:
                sampling_steps = 400
            else:
                sampling_steps = 500
    
    print(f"âš™ï¸  é‡‡æ ·æ­¥æ•°: {sampling_steps}")
    print(f"ğŸ“Š æ•°æ®é›†ç±»å‹: {dataset_name.upper()}")
    
    start_time = time.time()
    
    with torch.no_grad():
        # ä½¿ç”¨æ¨¡å‹çš„diffusionå¯¹è±¡è¿›è¡Œé‡‡æ ·
        samples = model.diffusion.sample(batch_size=num_samples)
    
    generation_time = time.time() - start_time
    print(f"â±ï¸  ç”Ÿæˆç”¨æ—¶: {generation_time:.2f}ç§’")
    print(f"ğŸš€ ç”Ÿæˆé€Ÿåº¦: {num_samples/generation_time:.1f} æ ·æœ¬/ç§’")
    
    # ä¿å­˜æ ·æœ¬
    if save_path:
        save_true_high_quality_samples(samples, save_path, model.image_size, dataset_name)
        print(f"ğŸ’¾ çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ ·æœ¬å·²ä¿å­˜åˆ°: {save_path}")
    
    return samples

def save_true_high_quality_samples(samples, path, image_size, dataset_name='unknown'):
    """ä¿å­˜çœŸæ­£çš„é«˜è´¨é‡æ ·æœ¬"""
    os.makedirs(os.path.dirname(path) if os.path.dirname(path) else '.', exist_ok=True)
    
    # è½¬æ¢åˆ°[0,1]èŒƒå›´
    samples = (samples + 1) / 2
    samples = torch.clamp(samples, 0, 1)
    
    # æ ¹æ®æ ·æœ¬æ•°é‡è°ƒæ•´ç½‘æ ¼
    n_samples = len(samples)
    if n_samples <= 4:
        nrow = 2
    elif n_samples <= 9:
        nrow = 3
    elif n_samples <= 16:
        nrow = 4
    elif n_samples <= 25:
        nrow = 5
    else:
        nrow = int(np.sqrt(n_samples))
    
    # åˆ›å»ºç½‘æ ¼
    grid = torchvision.utils.make_grid(samples, nrow=nrow, padding=4)
    grid_np = grid.permute(1, 2, 0).cpu().numpy()
    
    # æ ¹æ®åˆ†è¾¨ç‡å’Œæ•°æ®é›†è°ƒæ•´æ˜¾ç¤ºå¤§å°
    if image_size >= 96:
        fig_size = 16
    elif image_size >= 64:
        fig_size = 14
    else:
        fig_size = 12
    
    plt.figure(figsize=(fig_size, fig_size))
    plt.imshow(grid_np)
    plt.axis('off')
    
    # ç”Ÿæˆæ ‡é¢˜
    title = f'Generated Samples - {dataset_name.upper()} ({image_size}x{image_size})'
    if dataset_name == 'stl10':
        title += ' [åŸç”Ÿ96x96]'
    elif dataset_name == 'celeba':
        title += ' [åŸç”Ÿ64x64]'
    elif dataset_name == 'cifar10':
        title += ' [åŸç”Ÿ32x32]'
    else:
        title += ' [çœŸæ­£çš„é«˜åˆ†è¾¨ç‡]'
    
    plt.title(title, fontsize=16, fontweight='bold', pad=20)
    
    # é«˜è´¨é‡ä¿å­˜
    dpi = 300 if image_size >= 64 else 200
    plt.savefig(path, bbox_inches='tight', dpi=dpi, facecolor='white')
    plt.close()
    
    # åŒæ—¶ä¿å­˜å•ç‹¬çš„å›¾ç‰‡
    base_name = os.path.splitext(path)[0]
    individual_dir = f"{base_name}_individual"
    os.makedirs(individual_dir, exist_ok=True)
    
    for i, sample in enumerate(samples):
        sample_np = sample.permute(1, 2, 0).cpu().numpy()
        sample_np = (sample_np * 255).astype(np.uint8)
        img = Image.fromarray(sample_np)
        img.save(f"{individual_dir}/sample_{i+1:03d}.png")

def interpolate_true_high_res(model, num_steps=10, save_path=None, dataset_name='unknown'):
    """çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ’å€¼"""
    print(f"ğŸ”„ ç”ŸæˆçœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ’å€¼åºåˆ— ({num_steps} æ­¥)")
    
    device = model.device
    
    with torch.no_grad():
        # ç”Ÿæˆä¸¤ä¸ªéšæœºæ ·æœ¬
        sample1 = model.sample(batch_size=1)
        sample2 = model.sample(batch_size=1)
        
        # ä½¿ç”¨æ¨¡å‹çš„æ’å€¼æ–¹æ³•
        interpolated = model.interpolate(sample1, sample2, num_steps=num_steps)
    
    if save_path:
        save_true_interpolation_grid(interpolated, save_path, model.image_size, dataset_name)
        print(f"ğŸ’¾ çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ’å€¼åºåˆ—å·²ä¿å­˜åˆ°: {save_path}")
    
    return interpolated

def save_true_interpolation_grid(samples, path, image_size, dataset_name='unknown'):
    """ä¿å­˜çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ’å€¼ç½‘æ ¼"""
    os.makedirs(os.path.dirname(path) if os.path.dirname(path) else '.', exist_ok=True)
    
    samples = (samples + 1) / 2
    samples = torch.clamp(samples, 0, 1)
    
    # å•è¡Œç½‘æ ¼æ˜¾ç¤ºæ’å€¼è¿‡ç¨‹
    grid = torchvision.utils.make_grid(samples, nrow=len(samples), padding=2)
    grid_np = grid.permute(1, 2, 0).cpu().numpy()
    
    plt.figure(figsize=(len(samples) * 3, 3))
    plt.imshow(grid_np)
    plt.axis('off')
    
    title = f'Interpolation - {dataset_name.upper()} ({image_size}x{image_size})'
    plt.title(title, fontsize=14, fontweight='bold')
    
    plt.savefig(path, bbox_inches='tight', dpi=200, facecolor='white')
    plt.close()

def find_true_high_res_models():
    """æŸ¥æ‰¾train_true_high_res.pyè®­ç»ƒçš„æ¨¡å‹"""
    models = []
    
    # æ‰«æcheckpointsç›®å½•
    if os.path.exists('checkpoints'):
        for exp_dir in os.listdir('checkpoints'):
            exp_path = os.path.join('checkpoints', exp_dir)
            if os.path.isdir(exp_path) and ('native' in exp_dir or 'upsampled' in exp_dir):
                # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
                for file in os.listdir(exp_path):
                    if file.endswith('.pt'):
                        model_path = os.path.join(exp_path, file)
                        models.append({
                            'path': model_path,
                            'experiment': exp_dir,
                            'filename': file
                        })
    
    return models

def compare_true_high_res_models(model_paths, num_samples=4):
    """æ¯”è¾ƒä¸åŒçš„çœŸæ­£é«˜åˆ†è¾¨ç‡æ¨¡å‹"""
    print("ğŸ“Š æ¯”è¾ƒä¸åŒçš„çœŸæ­£é«˜åˆ†è¾¨ç‡æ¨¡å‹")
    
    results = {}
    
    for model_path in model_paths:
        if os.path.exists(model_path):
            try:
                model, image_size, dataset = load_true_high_res_model(model_path)
                samples = generate_true_high_res_samples(
                    model, 
                    num_samples=num_samples, 
                    show_progress=False,
                    dataset_name=dataset
                )
                results[f"{dataset.upper()}_{image_size}x{image_size}"] = {
                    'samples': samples,
                    'dataset': dataset,
                    'size': image_size
                }
                print(f"âœ… {dataset.upper()} {image_size}x{image_size} æ¨¡å‹æµ‹è¯•å®Œæˆ")
            except Exception as e:
                print(f"âŒ {model_path} åŠ è½½å¤±è´¥: {e}")
        else:
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    if results:
        # ä¿å­˜æ¯”è¾ƒå›¾
        save_true_comparison_grid(results, "true_high_res_comparison.png")
        print("ğŸ’¾ çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ¯”è¾ƒå›¾å·²ä¿å­˜")
    
    return results

def save_true_comparison_grid(results, path):
    """ä¿å­˜çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ¯”è¾ƒç½‘æ ¼"""
    if not results:
        return
    
    n_models = len(results)
    n_samples = 4
    
    fig, axes = plt.subplots(n_models, n_samples, figsize=(16, 4 * n_models))
    if n_models == 1:
        axes = axes.reshape(1, -1)
    
    for row, (model_name, data) in enumerate(results.items()):
        samples = data['samples']
        dataset = data['dataset']
        size = data['size']
        
        samples = (samples + 1) / 2
        samples = torch.clamp(samples, 0, 1)
        
        for col in range(min(n_samples, len(samples))):
            sample_np = samples[col].permute(1, 2, 0).cpu().numpy()
            axes[row, col].imshow(sample_np)
            axes[row, col].axis('off')
            if col == 0:
                label = f"{dataset.upper()}\n{size}x{size}"
                if dataset == 'stl10':
                    label += "\n[åŸç”Ÿ96x96]"
                elif dataset == 'celeba':
                    label += "\n[åŸç”Ÿ64x64]"
                elif dataset == 'cifar10':
                    label += "\n[åŸç”Ÿ32x32]"
                    
                axes[row, col].set_ylabel(label, fontsize=12, fontweight='bold')
    
    plt.suptitle('çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ¨¡å‹æ¯”è¾ƒ', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(path, bbox_inches='tight', dpi=200, facecolor='white')
    plt.close()

def main():
    """ä¸»å‡½æ•° - çœŸæ­£çš„é«˜åˆ†è¾¨ç‡æ¨ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(description='çœŸæ­£çš„é«˜åˆ†è¾¨ç‡DDPMæ¨ç†')
    parser.add_argument('--model', type=str, required=True, help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--samples', type=int, default=16, help='ç”Ÿæˆæ ·æœ¬æ•°é‡')
    parser.add_argument('--steps', type=int, default=None, help='é‡‡æ ·æ­¥æ•°')
    parser.add_argument('--output', type=str, default='true_high_res_samples.png', help='è¾“å‡ºè·¯å¾„')
    parser.add_argument('--interpolate', action='store_true', help='ç”Ÿæˆæ’å€¼åºåˆ—')
    parser.add_argument('--compare', nargs='+', help='æ¯”è¾ƒå¤šä¸ªæ¨¡å‹')
    
    args = parser.parse_args()
    
    if args.compare:
        # æ¯”è¾ƒæ¨¡å¼
        compare_true_high_res_models(args.compare)
    else:
        # å•æ¨¡å‹ç”Ÿæˆ
        model, image_size, dataset = load_true_high_res_model(args.model)
        
        # ç”Ÿæˆæ ·æœ¬
        samples = generate_true_high_res_samples(
            model, 
            num_samples=args.samples,
            save_path=args.output,
            sampling_steps=args.steps,
            dataset_name=dataset
        )
        
        # æ’å€¼ï¼ˆå¦‚æœè¯·æ±‚ï¼‰
        if args.interpolate:
            interpolate_path = f"interpolation_{dataset}_{image_size}x{image_size}.png"
            interpolate_true_high_res(model, save_path=interpolate_path, dataset_name=dataset)

if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œï¼Œä½¿ç”¨äº¤äº’æ¨¡å¼
    print("ğŸ¨ çœŸæ­£çš„é«˜åˆ†è¾¨ç‡DDPMæ¨ç†å·¥å…·")
    print("=" * 60)
    
    # æŸ¥æ‰¾train_true_high_res.pyè®­ç»ƒçš„æ¨¡å‹
    models = find_true_high_res_models()
    
    if not models:
        print("âŒ æœªæ‰¾åˆ°ç”±train_true_high_res.pyè®­ç»ƒçš„æ¨¡å‹")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ä¹‹ä¸€ï¼š")
        print("   python train_true_high_res.py stl10     # STL-10 (åŸç”Ÿ96x96)")
        print("   python train_true_high_res.py celeba    # CelebA (åŸç”Ÿ64x64)")
        print("   python train_true_high_res.py cifar10   # CIFAR-10 (åŸç”Ÿ32x32)")
        exit(1)
    
    print("ğŸ“‚ å‘ç°çš„çœŸæ­£é«˜åˆ†è¾¨ç‡æ¨¡å‹:")
    for i, model_info in enumerate(models):
        exp_name = model_info['experiment']
        filename = model_info['filename']
        print(f"   {i+1}. {exp_name}/{filename}")
    
    try:
        choice = int(input(f"\né€‰æ‹©æ¨¡å‹ (è¾“å…¥ç¼–å· 1-{len(models)}): ")) - 1
        if 0 <= choice < len(models):
            model_path = models[choice]['path']
            
            model, image_size, dataset = load_true_high_res_model(model_path)
            
            print("\nğŸ¯ ç”Ÿæˆé€‰é¡¹:")
            print("1. ç”Ÿæˆæ ·æœ¬")
            print("2. ç”Ÿæˆæ’å€¼åºåˆ—") 
            print("3. æ‰¹é‡ç”Ÿæˆ")
            print("4. è´¨é‡è¯„ä¼°")
            
            option = input("é€‰æ‹©æ“ä½œ (1-4): ")
            
            if option == "1":
                num_samples = int(input("æ ·æœ¬æ•°é‡ (é»˜è®¤16): ") or "16")
                output_path = f"generated_{dataset}_{image_size}x{image_size}_samples.png"
                generate_true_high_res_samples(
                    model, 
                    num_samples=num_samples, 
                    save_path=output_path,
                    dataset_name=dataset
                )
                
            elif option == "2":
                interpolate_true_high_res(
                    model, 
                    save_path=f"interpolation_{dataset}_{image_size}x{image_size}.png",
                    dataset_name=dataset
                )
                
            elif option == "3":
                batch_size = int(input("æ¯æ‰¹æ ·æœ¬æ•° (é»˜è®¤16): ") or "16")
                num_batches = int(input("æ‰¹æ¬¡æ•°é‡ (é»˜è®¤5): ") or "5")
                
                batch_dir = f"batch_generation_{dataset}_{image_size}x{image_size}"
                os.makedirs(batch_dir, exist_ok=True)
                
                for i in range(num_batches):
                    output_path = f"{batch_dir}/batch_{i+1}.png"
                    generate_true_high_res_samples(
                        model, 
                        num_samples=batch_size, 
                        save_path=output_path,
                        dataset_name=dataset
                    )
                    print(f"âœ… æ‰¹æ¬¡ {i+1}/{num_batches} å®Œæˆ")
                
                print("ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆï¼")
                
            elif option == "4":
                print("ğŸ” è´¨é‡è¯„ä¼°æ¨¡å¼")
                # ç”Ÿæˆå¤šä¸ªæ ·æœ¬è¿›è¡Œè´¨é‡è¯„ä¼°
                test_samples = [4, 9, 16, 25]
                
                for n in test_samples:
                    output_path = f"quality_test_{dataset}_{image_size}x{image_size}_{n}samples.png"
                    start_time = time.time()
                    generate_true_high_res_samples(
                        model, 
                        num_samples=n, 
                        save_path=output_path,
                        dataset_name=dataset
                    )
                    gen_time = time.time() - start_time
                    print(f"âœ… {n}æ ·æœ¬ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶{gen_time:.2f}ç§’")
                
                print("ğŸ“Š è´¨é‡è¯„ä¼°å®Œæˆï¼Œè¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except (ValueError, KeyboardInterrupt):
        print("\nğŸ‘‹ é€€å‡ºç¨‹åº") 