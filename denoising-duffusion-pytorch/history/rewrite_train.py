import torch
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import os
from ddpm_model import DDPMModel

def test_train_setup():
    """æµ‹è¯•è®­ç»ƒè®¾ç½®æ˜¯å¦æ­£å¸¸"""
    print("ğŸ” éªŒè¯è®­ç»ƒè„šæœ¬è®¾ç½®...")
    
    try:
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataloader, dataset = get_cifar10_dataloader(batch_size=4, image_size=32)
        print(f"âœ… æ•°æ®åŠ è½½æ­£å¸¸ - æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # æµ‹è¯•æ¨¡å‹åˆ›å»º
        model = DDPMModel(
            image_size=32,
            channels=3,
            dim=32,  # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
            dim_mults=(1, 2),
            timesteps=100
        )
        print("âœ… æ¨¡å‹åˆ›å»ºæ­£å¸¸")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡çš„è®­ç»ƒ
        data_iter = iter(dataloader)
        test_batch, _ = next(data_iter)
        
        optimizer = torch.optim.Adam(model.unet.parameters(), lr=1e-4)
        
        model.unet.train()
        optimizer.zero_grad()
        loss = model.train_step(test_batch)
        loss.backward()
        optimizer.step()
        
        print(f"âœ… è®­ç»ƒæ­¥éª¤æ­£å¸¸ - æµ‹è¯•æŸå¤±: {loss.item():.4f}")
        print("ğŸ‰ è®­ç»ƒè„šæœ¬éªŒè¯é€šè¿‡ï¼\n")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè„šæœ¬éªŒè¯å¤±è´¥: {e}")
        return False

def get_cifar10_dataloader(batch_size=32, image_size=32):
    """è·å–CIFAR-10æ•°æ®åŠ è½½å™¨"""
    transform = transforms.Compose([
        transforms.Resize(image_size),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # å½’ä¸€åŒ–åˆ°[-1, 1]
    ])
    
    dataset = torchvision.datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=transform
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2,
        pin_memory=True
    )
    
    return dataloader, dataset  # è¿”å›datasetä»¥ä¾¿è·å–é•¿åº¦

def train_ddpm(epochs=100, batch_size=32, learning_rate=1e-4, save_interval=20):
    """è®­ç»ƒDDPMæ¨¡å‹"""
    
    # åˆ›å»ºæ¨¡å‹
    model = DDPMModel(
        image_size=32,
        channels=3,
        dim=64,
        dim_mults=(1, 2, 4, 8),
        timesteps=1000
    )
    
    # è®¾ç½®ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.unet.parameters(), lr=learning_rate)
    
    # è·å–æ•°æ®åŠ è½½å™¨
    dataloader, dataset = get_cifar10_dataloader(batch_size=batch_size)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs('checkpoints', exist_ok=True)
    os.makedirs('samples', exist_ok=True)
    
    # è®­ç»ƒå†å²è®°å½•
    losses = []
    
    print(f"å¼€å§‹è®­ç»ƒDDPMæ¨¡å‹...")
    print(f"- è®­ç»ƒè½®æ•°: {epochs}")
    print(f"- æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"- å­¦ä¹ ç‡: {learning_rate}")
    print(f"- æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    for epoch in range(epochs):
        model.unet.train()
        epoch_losses = []
        
        pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}')
        for batch_idx, (data, _) in enumerate(pbar):
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            loss = model.train_step(data)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            epoch_losses.append(loss.item())
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        # è®°å½•å¹³å‡æŸå¤±
        avg_loss = np.mean(epoch_losses)
        losses.append(avg_loss)
        
        print(f'Epoch {epoch+1}, å¹³å‡æŸå¤±: {avg_loss:.4f}')
        
        # ä¿å­˜æ£€æŸ¥ç‚¹å’Œç”Ÿæˆæ ·æœ¬
        if (epoch + 1) % save_interval == 0:
            # ä¿å­˜æ¨¡å‹
            checkpoint_path = f'checkpoints/ddpm_epoch_{epoch+1}.pt'
            model.save_model(checkpoint_path)
            
            # ç”Ÿæˆæ ·æœ¬å¹¶ä¿å­˜
            model.unet.eval()
            with torch.no_grad():
                samples = model.sample(batch_size=16)
                save_samples(samples, f'samples/epoch_{epoch+1}_samples.png')
            
            # ä¿å­˜æŸå¤±æ›²çº¿
            plot_losses(losses, f'samples/loss_curve_epoch_{epoch+1}.png')
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_path = 'checkpoints/ddpm_final.pt'
    model.save_model(final_path)
    
    print("è®­ç»ƒå®Œæˆï¼")
    return model, losses

def save_samples(samples, path):
    """ä¿å­˜ç”Ÿæˆçš„æ ·æœ¬å›¾åƒ"""
    try:
        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        # å°†æ ·æœ¬ä»[-1, 1]è½¬æ¢åˆ°[0, 1]
        samples = (samples + 1) / 2
        samples = torch.clamp(samples, 0, 1)
        
        # åˆ›å»ºç½‘æ ¼å›¾åƒ
        grid = torchvision.utils.make_grid(samples, nrow=4, padding=2)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ä¿å­˜
        grid_np = grid.permute(1, 2, 0).cpu().numpy()
        
        plt.figure(figsize=(10, 10))
        plt.imshow(grid_np)
        plt.axis('off')
        plt.title('Generated Samples')
        plt.savefig(path, bbox_inches='tight', dpi=150)
        plt.close()
        
        print(f"æ ·æœ¬å·²ä¿å­˜åˆ°: {path}")
    except Exception as e:
        print(f"ä¿å­˜æ ·æœ¬æ—¶å‡ºé”™: {e}")

def plot_losses(losses, path):
    """ç»˜åˆ¶å¹¶ä¿å­˜æŸå¤±æ›²çº¿"""
    try:
        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        plt.figure(figsize=(10, 6))
        plt.plot(losses)
        plt.title('Training Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.grid(True)
        plt.savefig(path, bbox_inches='tight', dpi=150)
        plt.close()
        
        print(f"æŸå¤±æ›²çº¿å·²ä¿å­˜åˆ°: {path}")
    except Exception as e:
        print(f"ä¿å­˜æŸå¤±æ›²çº¿æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] == '--test':
        # åªè¿è¡ŒéªŒè¯æµ‹è¯•
        if test_train_setup():
            print("âœ… è®­ç»ƒè„šæœ¬å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å®Œæ•´è®­ç»ƒ")
        else:
            print("âŒ è¯·ä¿®å¤é—®é¢˜åå†å¼€å§‹è®­ç»ƒ")
        sys.exit()
    
    # è¿è¡ŒéªŒè¯æµ‹è¯•
    print("å¼€å§‹è®­ç»ƒå‰éªŒè¯...")
    if not test_train_setup():
        print("âŒ éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒè®¾ç½®")
        sys.exit(1)
    
    # å¼€å§‹å®Œæ•´è®­ç»ƒ
    try:
        model, losses = train_ddpm(
            epochs=50,  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
            batch_size=16,  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
            learning_rate=1e-4,
            save_interval=10
        )
        print("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc() 