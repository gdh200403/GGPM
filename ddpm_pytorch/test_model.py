"""
æµ‹è¯•æ¨¡å‹æ˜¯å¦å·¥ä½œæ­£å¸¸
"""
import torch
from model import UNet
from ddpm import DDPM
from config import Config

def test_model():
    print("æµ‹è¯•æ¨¡å‹...")
    print(f"ä½¿ç”¨è®¾å¤‡: {Config.device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = UNet(
        in_channels=Config.channels,
        dim=Config.dim,
        dim_mults=Config.dim_mults
    ).to(Config.device)
    
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # åˆ›å»ºDDPM
    ddpm = DDPM(
        model=model,
        timesteps=Config.timesteps,
        device=Config.device
    )
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 4
    x = torch.randn(batch_size, Config.channels, Config.image_size, Config.image_size).to(Config.device)
    t = torch.randint(0, Config.timesteps, (batch_size,)).to(Config.device)
    
    print("æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    with torch.no_grad():
        output = model(x, t)
        print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡ï¼")
    
    # æµ‹è¯•è®­ç»ƒæŸå¤±
    print("æµ‹è¯•è®­ç»ƒæŸå¤±è®¡ç®—...")
    loss = ddpm.training_loss(x)
    print(f"è®­ç»ƒæŸå¤±: {loss.item():.4f}")
    print("âœ… è®­ç»ƒæŸå¤±è®¡ç®—æµ‹è¯•é€šè¿‡ï¼")
    
    # æµ‹è¯•é‡‡æ ·
    print("æµ‹è¯•é‡‡æ ·ç”Ÿæˆ...")
    with torch.no_grad():
        samples = ddpm.sample((2, Config.channels, Config.image_size, Config.image_size))
        print(f"ç”Ÿæˆæ ·æœ¬å½¢çŠ¶: {samples.shape}")
        print("âœ… é‡‡æ ·ç”Ÿæˆæµ‹è¯•é€šè¿‡ï¼")
    
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹å·¥ä½œæ­£å¸¸ã€‚")

if __name__ == '__main__':
    test_model() 